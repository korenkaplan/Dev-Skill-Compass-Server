============= Database Integration: Insert the processed data into the database =============
- Create script to insert the core data into the database: Roles, Categories and Technologies.
- Create service classes for all the models to handle database interactions. (with testing)

============= Main Entrypoint And Cron job (depends on: Database Integration)  =============
- Create script to fetch a dictionary of techs and categories from the db before starting the main pipeline.
- Create the main pipeline: Scraping, text analysis, data processing, database insertion and update.
- Create the cron job to run the main pipeline each certain time.
- Temporary prepare sample data until the scraping will work.

============= WEB Scraping =============
- Learn how to scrape job listing sites.
- Handle the Chrome driver problem.
- Finish the module.
- Add the module to the main pipeline and replace sample data.

============= Repository & CV Adjustment =============
- Create a Readme.md file to the project.
- Create the CV and add the project to the CV.

============= Website Mockup =============
- Create a mockup for the website using figma
- List the endpoints and prepare functions for them.

============= Create a Restful API  =============
- Create specific endpoints for the website.

============= Build Website  =============
- Create a new React/streamlit project.

============= Deploy Website  =============
- Deploy the react site to netlify. adjust the cors
- Deploy the service to render adjust the allowed hosts.
- Host the postgresql and adjust the postgresql ENV variables.


 ==========================================  Done ==========================================
 - Text Analysis: get the tech words out of the job listings. -> Done.
 - Data Processing And Aggregation: process the tech words found in the job listings, and prepare it for database insert. -> Done.